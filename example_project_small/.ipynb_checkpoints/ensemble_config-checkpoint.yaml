--- # LLMs Multiagent Ensemble Application configuration - ensemble_config.yaml
# **Project**:
project_name: "small_example_project" # The name of the project, used to name some files, thus being legal as a substring of files.
data_folder_name: "data" # Optional: Deault: 'data'. The data folder name of this this Ensemble LLMs app within this prject home. 
# The aggregated outputs from each individual llm app will be '<data_folder>/<dataset_id>_<project_name>_aggregated.csv'.
# The ensemble prediction will be '<data_folder>/<dataset_id>_<project_name>_ensemble.csv'.
# **Prompt** to be used by each LLM agent:
prompt_file_path: "prompt_p07.txt" # the file with the template of the prompt, which will be incoporated with input data and output format.
prompt_id: "P07" # used to name some variables, intermediate files, and folders.
system_message_file_path: "system_message.txt" # Optional: Default:''. The system_message to a LLM. Alternatively, start prompt with this message.
# **Input data**:
input_data_path: "./data/tcga_pan_lung_samples.csv" # the path of input data csv file.
dataset_id: "lung" # to be used to name intermediate files and folders.
input_text_column_name: "text" # the column name for the text to feed to LLM, in input csv file
input_data_id_column_name: "pid" # the column name for record id (or row_id), in input csv file
# **Output data**:
var_val_list_path: "variable-value_list.json" # the json file with the variable-value list, specifying variables and their possible values.
json_output_template_path: "json_output_template.json" # the template of the expected json data generated by LLM
# **Specification of a pool of llm agent apps**:
llm_apps: 
# the folder for each llm_app will be f"<project_home>/{model_id}_{prompt_id}" 
# data folder for this llm_app will be f"<project_home>/{model_id}_{prompt_id}/data/" stabilityai/StableBeluga-13B
   - {framework: "OpenAI", # the framework to be used to facilitate LLM calling
      model: "gpt-4.1-mini", # the large language model (LLM) to use, use the model name OpenAI Api accepts.
      model_id: "gpt-4.1-mini", # make this id legal as part of the name for a file and a folder.
      }
   - {framework: "AzureOpenAI", # the framework to be used to facilitate LLM calling
      model: "gpt-4o-mini", # the large language model (LLM) to use, use the model name OpenAI Api accepts.
      model_id: "gpt-4o-mini", # make this id legal as part of the name for a file and a folder.
      }
   - {framework: "Ollama", # the framework to be used to facilitate LLM calling
      model: "llama3.1:70b", # the large language model (LLM) to use
      model_id: "llama31-70b", # make this model_id legal as part of the name for a file and a folder. 
      }
   - {framework: "Ollama", # the framework to be used to facilitate LLM calling
      model: "qwen2:72b", # the large language model (LLM) to use
      model_id: "qwen2-72b", # make this id legal as part of the name for variable, a file, and a folder.
      }
   - {framework: "Ollama", # the framework to be used to facilitate LLM calling
      model: "gemma:7b", # the large language model (LLM) to use
      model_id: "gemma7b", # make this id legal as part of the name for variable, a file, and a folder.
      }
...
 
