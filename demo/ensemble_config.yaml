--- # LLMs Multiagent Ensemble Application configuration - ensemble_config.yaml
# **Project**:
project_name: "Free7Demo" # The name of the project, used to name some files, thus being legal as a substring of files.
data_folder_name: "data" # The data folder name of this ensemble project.  Deault: 'data'. 
# The aggregated outputs from each individual llm app will be '<data_folder>/<dataset_id>_<project_name>_aggregated.csv'.
# The ensemble prediction will be '<data_folder>/<dataset_id>_<project_name>_ensemble.csv'.
#
# **Prompt** to be used by each LLM agent:
prompt_file_path: "prompt_S02.txt" # the file with the template of the prompt, which will be incoporated with input data and output format.
prompt_id: "S02" # used to name some variables, intermediate files, and folders.
system_message_file_path: "sys_msg_K01.txt" # The system_message to a LLM for setting a role with certain context, Default:''. 
# Alt: without specify, start prompt with system message.
#
# **Input data**:
input_data_path: "./data/ECG_data.csv" # the path of input data csv file.
dataset_id: "ECG" # to be used to name intermediate files and folders.
input_text_column_name: "text" # the column name for the text to feed to LLM, in input csv file
input_data_id_column_name: "note_id" # the column name for record id (or row_id), in input csv file
#
# **Output data**:
var_val_list_path: "variable-value_list.json" # the json file with the variable-value list, specifying variables and their possible values.
json_output_template_path: "json_output_template.json" # the template of the expected json data generated by LLM
#
# **Specification of a pool of llm agent apps**:
llm_apps: 
# the folder for each llm_app will be f"<project_home>/{model_id}_{prompt_id}" 
# data folder for this llm_app will be f"<project_home>/{model_id}_{prompt_id}/data/" 
#
# This demo uses the LLMs which were available (or most close one) at the time of ensemble LLMs reserach
   - {framework: "Ollama", # the framework to be used to facilitate LLM calling
      model: "stable-beluga:70b", # https://ollama.com/library/stable-beluga:70b
      model_id: "beluga-70b", # your name for the LLM, making this model_id legal as part of the name for a file or a folder. 
      }
   - {framework: "Ollama", # the framework to be used to facilitate LLM calling
      model: "gemma:7b", # https://ollama.com/library/gemma:7b
      model_id: "gemma7b", # your name for the LLM, making this id legal as part of the name for a file or a folder.
      }
   - {framework: "Ollama", # the framework to be used to facilitate LLM calling
      model: "llama3:70b", # https://ollama.com/library/llama3:70b
      model_id: "llama3-70b", # your name for the LLM, making this model_id legal as part of the name for a file or a folder. 
      }
   - {framework: "Ollama", 
      model: "mistral-openorca", # https://ollama.com/library/mistral-openorca
      model_id: "mistral-openorca", 
      }
   - {framework: "Ollama", 
      model: "openhermes", # https://ollama.com/library/openhermes:latest
      model_id: "openhermes", 
      }
   - {framework: "Ollama", 
      model: "qwen:72b", # https://ollama.com/library/qwen2:72b
      model_id: "qwen-72b", 
      }
   - {framework: "Ollama", 
      model: "qwen2:72b", # https://ollama.com/library/qwen2:72b
      model_id: "qwen2-72b", 
      }
# examples of GPT models      
   # - {framework: "OpenAI", # the framework to be used to facilitate LLM calling
   #    model: "gpt-4.1-mini", # the large language model (LLM) to use, use the model name OpenAI Api accepts.
   #    model_id: "gpt-4.1-mini", # make this id legal as part of the name for a file or a folder.
   #    }
   # - {framework: "AzureOpenAI", # the framework to be used to facilitate LLM calling
   #    model: "gpt-4o-mini", # the large language model (LLM) to use, use the model name OpenAI Api accepts.
   #    model_id: "gpt-4o-mini", # make this id legal as part of the name for a file or a folder.
   #    }
...
 
